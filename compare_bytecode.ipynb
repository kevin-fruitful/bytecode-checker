{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import binascii\n",
    "import cbor2\n",
    "import base58\n",
    "import datetime\n",
    "import json\n",
    "import requests\n",
    "from web3 import Web3\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from web3.contract import Contract\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython import get_ipython\n",
    "from git import Repo\n",
    "import tempfile\n",
    "import shutil\n",
    "import subprocess\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# load .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamondLoupeABI = [\n",
    "    {\n",
    "        \"constant\": True,\n",
    "        \"inputs\": [],\n",
    "        \"name\": \"facetAddresses\",\n",
    "        \"outputs\": [\n",
    "            {\n",
    "                \"internalType\": \"address[]\",\n",
    "                \"name\": \"facetAddresses_\",\n",
    "                \"type\": \"address[]\",\n",
    "            }\n",
    "        ],\n",
    "        \"payable\": False,\n",
    "        \"stateMutability\": \"view\",\n",
    "        \"type\": \"function\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompareBytecode:\n",
    "    def __init__(\n",
    "        self,\n",
    "        # contracts: dict = None,\n",
    "        json_with_diamond_address: str,\n",
    "        key_to_read_diamond_address: str,\n",
    "        w3: Web3,\n",
    "        contract_abi: dict,\n",
    "        dir_path_to_broadcasts: str = \"broadcast\",\n",
    "        dir_path_to_artifacts: str = \"forge-artifacts\",\n",
    "        additional_contracts: dict = None,\n",
    "        repos_with_build_option: tuple = None,\n",
    "        forge_path: str = None,\n",
    "    ):\n",
    "        self.json_with_diamond_address = json_with_diamond_address\n",
    "        self.key_to_read_diamond_address = key_to_read_diamond_address\n",
    "        self.w3 = w3\n",
    "        self.contract_abi = contract_abi\n",
    "        self.dir_path_to_broadcasts = dir_path_to_broadcasts\n",
    "        self.dir_path_to_artifacts = dir_path_to_artifacts\n",
    "        self.temp_dirs: dict = (\n",
    "            {}\n",
    "        )  # keeps track of temporary directories created for each commit\n",
    "        self.diamond_address = self.get_address_from_json(\n",
    "            self.key_to_read_diamond_address, self.json_with_diamond_address\n",
    "        )\n",
    "        self.repos_with_build_option = repos_with_build_option\n",
    "        self.forge_path = (\n",
    "            forge_path if forge_path is not None else shutil.which(\"forge\")\n",
    "        )\n",
    "        if self.forge_path is None:\n",
    "            raise Exception(\n",
    "                \"Could not find 'forge' executable. Please ensure it is installed and available in your PATH.\"\n",
    "            )\n",
    "\n",
    "        self.built_repos_commits = set()  # keeps track of built repos and commits\n",
    "        self.current_facet_addresses: list = None  # keeps track of facet addresses currently active on the proxy contract\n",
    "        self.contracts = (\n",
    "            self.match_contract_addresses_to_names()\n",
    "        )  # if there's no name to match, then this currently removes the contract from the list\n",
    "\n",
    "        # Add any additional self.contracts - override existing ones if needed\n",
    "        if additional_contracts:\n",
    "            for contract_name, address in additional_contracts.items():\n",
    "                if contract_name not in self.contracts:\n",
    "                    self.contracts[contract_name] = address\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"Contract '{contract_name}' already exists in the dictionary.\"\n",
    "                    )\n",
    "\n",
    "        self.metadata: dict = {}\n",
    "\n",
    "    def get_address_from_json(self, key=None, filename=None):\n",
    "        \"\"\"\n",
    "        Reads a JSON file and returns the value corresponding to a given key\n",
    "\n",
    "        Args:\n",
    "            key (str): key to look up in the JSON file. If None, self.key_to_read_diamond_address is used.\n",
    "            filename (str): name of the JSON file. If None, self.json_with_diamond_address is used.\n",
    "\n",
    "        Returns:\n",
    "            str: value corresponding to the given key or None if the key is not found\n",
    "        \"\"\"\n",
    "        key = self.key_to_read_diamond_address if key is None else key\n",
    "        filename = self.json_with_diamond_address if filename is None else filename\n",
    "\n",
    "        if not os.path.isfile(filename):\n",
    "            print(f\"File '{filename}' does not exist.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            with open(filename, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"File '{filename}' is not a valid JSON file.\")\n",
    "            return None\n",
    "\n",
    "        address = data.get(key)\n",
    "        if address is None:\n",
    "            print(f\"No address found for key '{key}' in {filename}.\")\n",
    "\n",
    "        return address\n",
    "\n",
    "    def is_notebook(self):\n",
    "        \"\"\"Check if the script is running in a Jupyter notebook\"\"\"\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        return shell == \"ZMQInteractiveShell\"\n",
    "\n",
    "    def get_input(self, prompt):\n",
    "        \"\"\"Get input from user, compatible with both Jupyter notebook and CLI\"\"\"\n",
    "        if self.is_notebook():\n",
    "            input_widget = widgets.Text(\n",
    "                value=\"\",\n",
    "                placeholder=\"Enter new address\",\n",
    "                description=prompt,\n",
    "                disabled=False,\n",
    "                layout=widgets.Layout(\n",
    "                    width=\"auto\"\n",
    "                ),  # adjusts the width of the input box\n",
    "            )\n",
    "            input_widget.style.description_width = (\n",
    "                \"initial\"  # adjusts the width of the description\n",
    "            )\n",
    "            display(input_widget)\n",
    "\n",
    "            # Wait for input in Jupyter\n",
    "            while not input_widget.value:\n",
    "                pass\n",
    "            return input_widget.value\n",
    "        else:\n",
    "            # Get input in CLI\n",
    "            return input(prompt)\n",
    "\n",
    "    def checkout_and_build(self, repo=None, commit=None):\n",
    "        \"\"\"\n",
    "        Checks out a specific commit in the repository and runs `forge build`.\n",
    "        If no repo and commit are specified, checks `self.repos_with_build_option`.\n",
    "\n",
    "        Args:\n",
    "            repo (str, optional): The repository to use. Defaults to None.\n",
    "            commit (str, optional): The commit to checkout. Defaults to None.\n",
    "        \"\"\"\n",
    "\n",
    "        # If no repo and commit are specified, use the ones from self.repos_with_build_option\n",
    "        # if repo is None and commit is None:\n",
    "        for (repo, commit), options in self.repos_with_build_option.items():\n",
    "            if options[\"build\"] and commit not in self.built_repos_commits:\n",
    "                self.temp_dirs[commit] = self.perform_build(repo, commit)\n",
    "                self.built_repos_commits.add(commit)\n",
    "\n",
    "    def perform_build(self, repo, commit):\n",
    "        \"\"\"\n",
    "        Performs the git clone, checkout, and forge build operations for the specified repo and commit.\n",
    "\n",
    "        Args:\n",
    "            repo (str): The repository to use.\n",
    "            commit (str): The commit to checkout.\n",
    "        \"\"\"\n",
    "        # Save the initial working directory\n",
    "        start_dir = os.getcwd()\n",
    "\n",
    "        # Create a temporary directory\n",
    "        with tempfile.TemporaryDirectory() as tempdir:\n",
    "            # Clone the repository into the temporary directory\n",
    "            clone_command = [\"git\", \"clone\", repo, tempdir]\n",
    "            subprocess.run(clone_command, check=True)\n",
    "\n",
    "            # Checkout the specific commit\n",
    "            os.chdir(tempdir)\n",
    "            checkout_command = [\"git\", \"checkout\", commit]\n",
    "            subprocess.run(checkout_command, check=True)\n",
    "\n",
    "            # Deinitialize any existing submodules\n",
    "            # deinit_command = [\"git\", \"submodule\", \"deinit\", \"--force\", \".\"]\n",
    "            # subprocess.run(deinit_command, check=True)\n",
    "\n",
    "            # Update and initialize submodules\n",
    "            update_command = [\"git\", \"submodule\", \"update\", \"--init\", \"--recursive\"]\n",
    "            subprocess.run(update_command, check=True)\n",
    "\n",
    "            # Get short commit hash\n",
    "            get_commit_hash_command = [\"git\", \"rev-parse\", \"--short\", commit]\n",
    "            commit_hash = subprocess.run(\n",
    "                get_commit_hash_command, capture_output=True, text=True\n",
    "            ).stdout.strip()\n",
    "\n",
    "            # Create a new directory for these artifacts with the commit hash in the name\n",
    "            temp_artifacts_dir = os.path.join(tempdir, f\"{commit_hash}_artifacts\")\n",
    "            os.makedirs(temp_artifacts_dir, exist_ok=True)\n",
    "\n",
    "            # Run `forge build`\n",
    "            build_command = [\n",
    "                self.forge_path,\n",
    "                \"build\",\n",
    "                \"--out\",\n",
    "                temp_artifacts_dir,\n",
    "                \"--skip\",\n",
    "                \"script\",\n",
    "                \"test\",\n",
    "                \"D0\",\n",
    "                \"DeploymentHelpers\",\n",
    "            ]\n",
    "            subprocess.run(build_command, check=True)\n",
    "\n",
    "            # Switch back to the initial directory\n",
    "            os.chdir(start_dir)\n",
    "\n",
    "            # Create a directory for these artifacts with the commit hash in the name in a persistent location\n",
    "            new_artifacts_dir = os.path.join(\n",
    "                start_dir, \"temp_artifacts\", f\"{commit_hash}_artifacts\"\n",
    "            )\n",
    "            os.makedirs(new_artifacts_dir, exist_ok=True)\n",
    "\n",
    "            # Copy the files from the temporary directory to the new directory\n",
    "            shutil.copytree(temp_artifacts_dir, new_artifacts_dir, dirs_exist_ok=True)\n",
    "\n",
    "        return new_artifacts_dir\n",
    "\n",
    "    def get_current_facet_addresses(self, diamond_address=None):\n",
    "        if diamond_address is None:\n",
    "            diamond_address = self.diamond_address\n",
    "\n",
    "        diamond_loupe = self.w3.eth.contract(\n",
    "            address=diamond_address, abi=self.contract_abi\n",
    "        )\n",
    "\n",
    "        # Call the facetAddresses() method\n",
    "        try:\n",
    "            self.current_facet_addresses = (\n",
    "                diamond_loupe.functions.facetAddresses().call()\n",
    "            )\n",
    "\n",
    "            return self.current_facet_addresses\n",
    "\n",
    "        except:\n",
    "            print(\"Failed to call facetAddresses() method\")\n",
    "\n",
    "    def create_contract_address_list(self):\n",
    "        # Get the facet addresses\n",
    "        facet_addresses = self.get_current_facet_addresses()\n",
    "\n",
    "        contract_address_list = [self.diamond_address] + facet_addresses\n",
    "\n",
    "        return contract_address_list\n",
    "\n",
    "    def match_contract_addresses_to_names(self, contract_addresses: str = None):\n",
    "        \"\"\"\n",
    "        Create a dictionary of contract names and addresses.\n",
    "\n",
    "        Args:\n",
    "            contract_addresses (str): The addresses of the contract.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary with contract names as keys and contract addresses as values.\n",
    "        \"\"\"\n",
    "        contract_dict = {}\n",
    "        reverse_dict = {}\n",
    "\n",
    "        # Get the contract addresses\n",
    "        if contract_addresses is None:\n",
    "            contract_addresses = self.create_contract_address_list()\n",
    "\n",
    "        # Traverse the directory and find all JSON files\n",
    "        root = self.dir_path_to_broadcasts\n",
    "        json_files = []\n",
    "        for dirpath, dirnames, filenames in os.walk(root):\n",
    "            # check if directory ends with key_to_read_diamond_address\n",
    "            if dirpath.endswith(self.key_to_read_diamond_address):\n",
    "                # check if directory is not 'dry-run'\n",
    "                if \"dry-run\" not in dirpath:\n",
    "                    for filename in filenames:\n",
    "                        if filename.endswith(\".json\"):\n",
    "                            json_path = os.path.join(dirpath, filename)\n",
    "                            json_files.append(json_path)\n",
    "\n",
    "        # Sort the files by modification time in reverse order\n",
    "        sorted_files = sorted(json_files, key=os.path.getmtime, reverse=True)\n",
    "        for json_path in sorted_files:\n",
    "            with open(json_path, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                transactions = data.get(\"transactions\", [])\n",
    "                for transaction in transactions:\n",
    "                    # Check if the contractAddress matches any of the facet addresses\n",
    "                    if transaction.get(\"contractAddress\") in contract_addresses:\n",
    "                        contract_name = transaction.get(\"contractName\")\n",
    "                        contract_address = transaction.get(\"contractAddress\")\n",
    "                        # If address not in contract_dict or is same as existing key\n",
    "                        if (\n",
    "                            contract_address not in contract_dict.values()\n",
    "                            or contract_dict.get(contract_name) == contract_address\n",
    "                        ):\n",
    "                            contract_dict[contract_name] = contract_address\n",
    "                            # Update the reverse dictionary\n",
    "                            if (\n",
    "                                contract_address in reverse_dict\n",
    "                                and contract_name != reverse_dict[contract_address]\n",
    "                            ):\n",
    "                                reverse_dict[contract_address].add(contract_name)\n",
    "                            else:\n",
    "                                reverse_dict[contract_address] = {contract_name}\n",
    "                        else:\n",
    "                            duplicate_keys = [\n",
    "                                k\n",
    "                                for k, v in contract_dict.items()\n",
    "                                if v == contract_address\n",
    "                            ]\n",
    "                            print(\n",
    "                                f\"Duplicate address {contract_address} found for contracts: {duplicate_keys} and {contract_name} in {filename}\"\n",
    "                            )\n",
    "                            duplicate_keys.append(contract_name)\n",
    "                            print(\n",
    "                                \"Which contract would you like to provide a new address for?\"\n",
    "                            )\n",
    "                            for i, key in enumerate(duplicate_keys):\n",
    "                                print(f\"{i+1}: {key}\")\n",
    "                            selected_index = (\n",
    "                                int(\n",
    "                                    input(\n",
    "                                        \"Enter the number corresponding to your selection: \"\n",
    "                                    )\n",
    "                                )\n",
    "                                - 1\n",
    "                            )\n",
    "                            selected_key = duplicate_keys[selected_index]\n",
    "                            new_address = input(\n",
    "                                \"Enter new address for the selected contract: \"\n",
    "                            )\n",
    "                            contract_dict[selected_key] = new_address\n",
    "\n",
    "        return contract_dict\n",
    "\n",
    "    def verify_contracts_are_active(self, contracts: dict = None):\n",
    "        \"\"\"\n",
    "        Verifies that the contract is active by calling the `getFacetAddresses()` method.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the facet addresses\n",
    "        facet_addresses = self.get_current_facet_addresses()\n",
    "\n",
    "        if contracts is None:\n",
    "            contracts = self.contracts\n",
    "\n",
    "        active_contracts: dict = {}\n",
    "\n",
    "        # Check if the contract address is in the list of facet addresses\n",
    "        for contract_name, contract_address in contracts.items():\n",
    "            if contract_address in facet_addresses:\n",
    "                active_contracts[contract_name] = True\n",
    "            else:\n",
    "                active_contracts[contract_name] = False\n",
    "                \n",
    "            # Assume the proxy address in self.contracts is active\n",
    "            if contract_address == self.diamond_address:\n",
    "                active_contracts[contract_name] = True\n",
    "\n",
    "        return active_contracts\n",
    "\n",
    "    def get_bytecodes(self, contracts):\n",
    "        \"\"\"\n",
    "        Extracts bytecode from given contracts' artifact JSON file\n",
    "\n",
    "        Args:\n",
    "            contracts (dict): dictionary of contract names and addresses.\n",
    "\n",
    "        Returns:\n",
    "            dict: dictionary of contract names and their bytecodes\n",
    "        \"\"\"\n",
    "        bytecodes = {}\n",
    "\n",
    "        for contract_name in contracts.keys():\n",
    "            # Check if the contract should be read from a specific repo and commit\n",
    "            for (repo, commit_hash), options in self.repos_with_build_option.items():\n",
    "                if contract_name in options.get(\"contracts\", []):\n",
    "                    # Update the root path to the temporary directory for this contract\n",
    "                    if options[\"build\"] == True:\n",
    "                        json_path = os.path.join(\n",
    "                            self.temp_dirs[commit_hash],\n",
    "                            f\"{contract_name}.sol\",\n",
    "                            f\"{contract_name}.json\",\n",
    "                        )\n",
    "                    else:\n",
    "                        json_path = os.path.join(\n",
    "                            \"temp_artifacts\",\n",
    "                            f\"{commit_hash}_artifacts\",\n",
    "                            f\"{contract_name}.sol\",\n",
    "                            f\"{contract_name}.json\",\n",
    "                        )\n",
    "\n",
    "                else:\n",
    "                    json_path = os.path.join(\n",
    "                        self.dir_path_to_artifacts,\n",
    "                        f\"{contract_name}.sol\",\n",
    "                        f\"{contract_name}.json\",\n",
    "                    )\n",
    "\n",
    "                with open(json_path) as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                bytecode = data[\"deployedBytecode\"][\"object\"]\n",
    "                if bytecode == \"\":\n",
    "                    print(f\"Bytecode for contract '{contract_name}' is empty.\")\n",
    "                bytecodes[contract_name] = bytecode\n",
    "\n",
    "        return bytecodes\n",
    "\n",
    "    def get_onchain_bytecodes(self, contracts):\n",
    "        \"\"\"\n",
    "        Retrieves on-chain runtime bytecodes for given contracts\n",
    "\n",
    "        Args:\n",
    "            contracts (dict): dictionary of contract names and addresses.\n",
    "\n",
    "        Returns:\n",
    "            dict: dictionary of contract names and their on-chain runtime bytecodes\n",
    "        \"\"\"\n",
    "        onchain_bytecodes = {}\n",
    "\n",
    "        for contract_name, contract_address in contracts.items():\n",
    "            onchain_bytecode = self.w3.eth.get_code(contract_address).hex()\n",
    "            onchain_bytecodes[contract_name] = onchain_bytecode\n",
    "\n",
    "        return onchain_bytecodes\n",
    "\n",
    "    def get_metadata_hash_bytecode(self, bytecode):\n",
    "        # todo fix prefix\n",
    "        prefix = \"a264\"\n",
    "        start_index = bytecode.find(prefix)\n",
    "\n",
    "        while start_index != -1:\n",
    "            try:\n",
    "                metadata_hex = bytecode[start_index:]\n",
    "                metadata_hash_bytecode = binascii.unhexlify(metadata_hex)\n",
    "\n",
    "                self.metadata[bytecode] = metadata_hash_bytecode\n",
    "\n",
    "                return metadata_hash_bytecode, start_index\n",
    "            except (ValueError, EOFError):\n",
    "                start_index = bytecode.find(prefix, start_index + 1)\n",
    "\n",
    "        return None, -1\n",
    "\n",
    "    def get_ipfs_hash(self, metadata_hash_bytecode):\n",
    "        cbor_decoded_metadata_hash_bytecode: dict = cbor2.loads(metadata_hash_bytecode)\n",
    "        hex_ipfs_hash = cbor_decoded_metadata_hash_bytecode[\"ipfs\"]\n",
    "\n",
    "        ipfs_hash = base58.b58encode(hex_ipfs_hash).decode(\"utf-8\")\n",
    "\n",
    "        return ipfs_hash\n",
    "\n",
    "    def get_metadata_from_ipfs(self, ipfs_hash):\n",
    "        # Use an IPFS gateway to fetch the data\n",
    "        response = requests.get(f\"https://ipfs.io/ipfs/{ipfs_hash}\")\n",
    "\n",
    "        # The actual metadata is usually a JSON file\n",
    "        metadata = response.json()\n",
    "\n",
    "        pprint.pprint(metadata)\n",
    "\n",
    "    def remove_metadata_hash_bytecode(self, bytecode):\n",
    "        md, idx = self.get_metadata_hash_bytecode(bytecode)\n",
    "        if idx != -1:\n",
    "            return bytecode[:idx]\n",
    "        return bytecode\n",
    "\n",
    "    def are_bytecodes_matching(self, bytecode1, bytecode2):\n",
    "        return bytecode1 == bytecode2\n",
    "\n",
    "    def compare_bytecodes(self, bytecodes1, bytecodes2):\n",
    "        \"\"\"\n",
    "        Compares bytecodes for each contract in two given dictionaries\n",
    "\n",
    "        Args:\n",
    "            bytecodes1 (dict): dictionary of contract names and their bytecodes\n",
    "            bytecodes2 (dict): dictionary of contract names and their bytecodes\n",
    "\n",
    "        Returns:\n",
    "            dict: dictionary of contract names and boolean values indicating if bytecodes are different\n",
    "        \"\"\"\n",
    "        are_different_with_metadata_bytecode_hash = {}\n",
    "        are_different_without_metadata_bytecode_hash = {}\n",
    "        for contract_name in bytecodes1.keys():\n",
    "            are_different_with_metadata_bytecode_hash[\n",
    "                contract_name\n",
    "            ] = self.are_bytecodes_matching(\n",
    "                bytecodes1[contract_name], bytecodes2.get(contract_name, \"\")\n",
    "            )\n",
    "\n",
    "            are_different_without_metadata_bytecode_hash[\n",
    "                contract_name\n",
    "            ] = self.are_bytecodes_matching(\n",
    "                self.remove_metadata_hash_bytecode(bytecodes1[contract_name]),\n",
    "                self.remove_metadata_hash_bytecode(bytecodes2.get(contract_name, \"\")),\n",
    "            )\n",
    "\n",
    "        return (\n",
    "            are_different_with_metadata_bytecode_hash,\n",
    "            are_different_without_metadata_bytecode_hash,\n",
    "        )\n",
    "\n",
    "    def compare_contract_bytecodes(self):\n",
    "        # checkout and build as needed\n",
    "        self.checkout_and_build()\n",
    "\n",
    "        (\n",
    "            are_different_with_metadata_bytecode_hash,\n",
    "            are_different_without_metadata_bytecode_hash,\n",
    "        ) = self.compare_bytecodes(\n",
    "            self.get_bytecodes(self.contracts),\n",
    "            self.get_onchain_bytecodes(self.contracts),\n",
    "        )\n",
    "\n",
    "        self.print_contracts_info(\n",
    "            self.merge_dicts(\n",
    "                self.contracts,\n",
    "                are_different_with_metadata_bytecode_hash,\n",
    "                are_different_without_metadata_bytecode_hash,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def merge_dicts(\n",
    "        self, contract_dict, comparison_with_metadata, comparison_without_metadata\n",
    "    ):\n",
    "        merged_dict = {}\n",
    "        for key in contract_dict:\n",
    "            merged_dict[key] = {\n",
    "                \"address\": contract_dict[key],\n",
    "                \"comparison_with_metadata\": comparison_with_metadata[key],\n",
    "                \"comparison_without_metadata\": comparison_without_metadata[key],\n",
    "            }\n",
    "\n",
    "        return self.merge_commit_hashes(merged_dict)\n",
    "\n",
    "    def merge_commit_hashes(self, existing_dict):\n",
    "        merged_dict = {}\n",
    "        for (repo, commit_hash), data in self.repos_with_build_option.items():\n",
    "            for contract in data[\"contracts\"]:\n",
    "                if contract in existing_dict:\n",
    "                    existing_dict[contract][\"commit_hash\"] = commit_hash\n",
    "                    merged_dict[contract] = existing_dict[contract]\n",
    "        return merged_dict\n",
    "\n",
    "    # def print_contracts_info(self, merged_dict):\n",
    "    #     base_url = \"https://etherscan.io/address/\"\n",
    "    #     for contract_name, info in merged_dict.items():\n",
    "    #         comparison_result = \"✅\" if info[\"comparison_result\"] else \"❌\"\n",
    "    #         clickable_address = base_url + info[\"address\"] + \"#code\"\n",
    "    #         display(\n",
    "    #             Markdown(\n",
    "    #                 f\"{comparison_result} {contract_name}: [{info['address']}]({clickable_address})\"\n",
    "    #             )\n",
    "    #         )\n",
    "    def print_contracts_info(self, merged_dict):\n",
    "        base_url = \"https://etherscan.io/address/\"\n",
    "        active_facet_addresses = self.verify_contracts_are_active()\n",
    "\n",
    "        chain_id = self.w3.eth.chain_id\n",
    "        block_number = self.w3.eth.block_number\n",
    "        timestamp = self.w3.eth.get_block(block_number).timestamp\n",
    "        # Convert timestamp to datetime\n",
    "        dt = datetime.datetime.utcfromtimestamp(timestamp)\n",
    "\n",
    "        # Convert datetime to ISO 8601 format\n",
    "        iso8601_time = dt.isoformat()\n",
    "\n",
    "        with open(\"bytecode_verification_report.md\", \"w\") as file:\n",
    "            file.write(\"# Bytecode Verification Report\\n\\n\")\n",
    "\n",
    "            file.write(\n",
    "                f\"## Network {chain_id}, block number {block_number} ({iso8601_time})\\n\\n\"\n",
    "            )\n",
    "\n",
    "            file.write(f\"Proxy address: `{self.diamond_address}`\\n\\n\")\n",
    "            \n",
    "            file.write(f\"Number of active facets: `{len(self.current_facet_addresses)}`\\n\\n\")\n",
    "\n",
    "            file.write(\n",
    "                \"| Contract Name | Address | Active | Commit Hash | Comparison with Metadata | Comparison without Metadata |\\n\"\n",
    "            )\n",
    "            file.write(\n",
    "                \"|---------------|---------|--------|-------------|-------------------------|-----------------------------|\\n\"\n",
    "            )\n",
    "\n",
    "            for contract_name, info in merged_dict.items():\n",
    "                comparison_with_metadata = (\n",
    "                    \"✅\" if info[\"comparison_with_metadata\"] else \"❌\"\n",
    "                )\n",
    "                comparison_without_metadata = (\n",
    "                    \"✅\" if info[\"comparison_without_metadata\"] else \"❌\"\n",
    "                )\n",
    "                clickable_address = base_url + info[\"address\"] + \"#code\"\n",
    "                active = \"✅\" if active_facet_addresses[contract_name] else \"❌\"\n",
    "                commit_hash = info[\"commit_hash\"]\n",
    "\n",
    "                file.write(\n",
    "                    f\"| {contract_name} | [{info['address']}]({clickable_address}) | {active} | {commit_hash} | {comparison_with_metadata} | {comparison_without_metadata} |\\n\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORGE_PATH = \"/Users/kevinpark/.foundry/bin/forge\"\n",
    "PROJECT_ROOT = os.path.join(\"/\", \"Users\", \"kevinpark\", \"dev\", \"nayms\", \"v3-extoken\")\n",
    "repos_with_build_option = {\n",
    "    (PROJECT_ROOT, \"69ed11f7\"): {\n",
    "        \"build\": False,\n",
    "        \"contracts\": [\n",
    "            \"ACLFacet\",\n",
    "            \"AdminFacet\",\n",
    "            \"EntityFacet\",\n",
    "            \"GovernanceFacet\",\n",
    "            \"MarketFacet\",\n",
    "            \"NaymsTokenFacet\",\n",
    "            \"PhasedDiamondCutFacet\",\n",
    "            \"SimplePolicyFacet\",\n",
    "            \"SystemFacet\",\n",
    "            \"TokenizedVaultFacet\",\n",
    "            \"TokenizedVaultIOFacet\",\n",
    "            \"UserFacet\",\n",
    "        ],\n",
    "    },\n",
    "    (PROJECT_ROOT, \"9de0e394\"): {\n",
    "        \"build\": False,\n",
    "        \"contracts\": [\"Nayms\", \"NaymsOwnershipFacet\", \"DiamondLoupeFacet\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "json_with_diamond_address = os.path.join(PROJECT_ROOT, \"deployedAddresses.json\")\n",
    "key_to_read_diamond_address = \"1\"  # update with your key to read proxy address\n",
    "web3_instance = Web3(\n",
    "    Web3.HTTPProvider(os.getenv(\"ETH_MAINNET_RPC_URL\"))\n",
    ")  # update with your provider details\n",
    "contract_abi = diamondLoupeABI\n",
    "dir_path_to_broadcasts = os.path.join(\n",
    "    PROJECT_ROOT, \"broadcast\"\n",
    ")  # update with your broadcasts directory path\n",
    "dir_path_to_artifacts = os.path.join(\n",
    "    PROJECT_ROOT, \"forge-artifacts\"\n",
    ")  # update with your artifacts directory path\n",
    "additional_contracts = {\n",
    "    \"NaymsOwnershipFacet\": \"0x073C1a072845D1d87f42309af9911bd3c07fC599\",\n",
    "    \"DiamondLoupeFacet\": \"0x0318ff107aFA55E3dc658cEA06748d0c35fbEC73\",\n",
    "}\n",
    "compare_bytecode = CompareBytecode(\n",
    "    json_with_diamond_address=json_with_diamond_address,\n",
    "    key_to_read_diamond_address=key_to_read_diamond_address,\n",
    "    dir_path_to_broadcasts=dir_path_to_broadcasts,\n",
    "    dir_path_to_artifacts=dir_path_to_artifacts,\n",
    "    w3=web3_instance,\n",
    "    contract_abi=contract_abi,\n",
    "    additional_contracts=additional_contracts,\n",
    "    repos_with_build_option=repos_with_build_option,\n",
    "    forge_path=FORGE_PATH,\n",
    ")\n",
    "\n",
    "compare_bytecode.compare_contract_bytecodes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
